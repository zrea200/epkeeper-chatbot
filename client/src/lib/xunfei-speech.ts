/**
 * è®¯é£è¯­éŸ³æœåŠ¡å·¥å…·
 * æ”¯æŒè¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆï¼ˆé€šè¿‡æœåŠ¡ç«¯ä»£ç†ï¼‰
 */

import XUNFEI_SPEECH_CONFIG from '@/config/xunfei-speech-config';

/**
 * æ£€æµ‹æµè§ˆå™¨ç¯å¢ƒä¿¡æ¯
 */
function getBrowserInfo(): {
  userAgent: string;
  isWeChat: boolean;
  isMobile: boolean;
  isIOS: boolean;
  isAndroid: boolean;
} {
  const ua = navigator.userAgent.toLowerCase();
  return {
    userAgent: ua,
    isWeChat: /micromessenger/.test(ua),
    isMobile: /mobile|android|iphone|ipad/.test(ua),
    isIOS: /iphone|ipad|ipod/.test(ua),
    isAndroid: /android/.test(ua),
  };
}

/**
 * æ£€æµ‹æµè§ˆå™¨æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
 */
function getSupportedMimeType(): string {
  const browserInfo = getBrowserInfo();
  console.log('ğŸ” æµè§ˆå™¨ç¯å¢ƒæ£€æµ‹:', browserInfo);
  
  const mimeTypes = [
    'audio/mp4',
    'audio/aac',
    'audio/mpeg',
    'audio/ogg',
    'audio/webm;codecs=opus',
    'audio/webm',
  ];

  const supportedTypes: string[] = [];
  for (const mimeType of mimeTypes) {
    if (MediaRecorder.isTypeSupported(mimeType)) {
      supportedTypes.push(mimeType);
    }
  }

  console.log('ğŸ“‹ æ”¯æŒçš„éŸ³é¢‘æ ¼å¼åˆ—è¡¨:', supportedTypes);

  if (supportedTypes.length > 0) {
    const selectedType = supportedTypes[0];
    console.log('âœ… é€‰æ‹©ä½¿ç”¨çš„éŸ³é¢‘æ ¼å¼:', selectedType);
    return selectedType;
  }

  console.warn('âš ï¸ æœªæ£€æµ‹åˆ°æ˜ç¡®çš„éŸ³é¢‘æ ¼å¼æ”¯æŒï¼Œä½¿ç”¨é»˜è®¤ audio/webm');
  return 'audio/webm';
}

/**
 * è®¯é£è¯­éŸ³è¯†åˆ«ç±»
 */
export class XunfeiSpeechRecognizer {
  private mediaRecorder: MediaRecorder | null = null;
  private audioChunks: Blob[] = [];
  private isListening: boolean = false;
  private onResultCallback?: (text: string) => void;
  private onErrorCallback?: (error: string) => void;
  private currentMimeType: string = 'audio/webm';

  /**
   * å¼€å§‹è¯­éŸ³è¯†åˆ«
   */
  async start(onResult: (text: string) => void, onError?: (error: string) => void) {
    if (this.isListening) {
      return;
    }

    this.onResultCallback = onResult;
    this.onErrorCallback = onError;
    this.audioChunks = [];

    try {
      const browserInfo = getBrowserInfo();
      console.log('ğŸ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼ˆè®¯é£ï¼‰ï¼Œç¯å¢ƒä¿¡æ¯:', browserInfo);
      
      // è¯·æ±‚éº¦å…‹é£æƒé™
      const audioConstraints: MediaTrackConstraints = {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
        sampleRate: 16000,
        channelCount: 1,
      };
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: audioConstraints 
      });
      
      const audioTrack = stream.getAudioTracks()[0];
      const settings = audioTrack.getSettings();
      console.log('âœ… éº¦å…‹é£æƒé™è·å–æˆåŠŸï¼ŒéŸ³é¢‘å‚æ•°:', {
        é‡‡æ ·ç‡: settings.sampleRate,
        å£°é“æ•°: settings.channelCount,
      });
      
      // æ£€æµ‹å¹¶ä½¿ç”¨æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
      const mimeType = getSupportedMimeType();
      this.currentMimeType = mimeType;
      console.log('ğŸ¤ ä½¿ç”¨éŸ³é¢‘æ ¼å¼:', mimeType);
      
      // åˆ›å»º MediaRecorder
      let recorderCreated = false;
      const preferredMimeTypes = [
        mimeType,
        'audio/webm;codecs=opus',
        'audio/webm',
      ];
      
      for (const preferredType of preferredMimeTypes) {
        try {
          if (MediaRecorder.isTypeSupported(preferredType)) {
            this.mediaRecorder = new MediaRecorder(stream, {
              mimeType: preferredType,
              audioBitsPerSecond: 128000,
            });
            this.currentMimeType = preferredType;
            console.log('âœ… MediaRecorder åˆ›å»ºæˆåŠŸï¼Œä½¿ç”¨æ ¼å¼:', preferredType);
            recorderCreated = true;
            break;
          }
        } catch (err) {
          // ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªæ ¼å¼
        }
      }
      
      if (!recorderCreated) {
        console.warn('âš ï¸ æ— æ³•åˆ›å»ºæŒ‡å®šæ ¼å¼çš„MediaRecorderï¼Œä½¿ç”¨é»˜è®¤é…ç½®');
        try {
          this.mediaRecorder = new MediaRecorder(stream, {
            audioBitsPerSecond: 128000,
          });
        } catch (recorderError: any) {
          console.error('âŒ MediaRecorder åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨æœ€ç®€é…ç½®:', recorderError);
          this.mediaRecorder = new MediaRecorder(stream);
        }
        if (this.mediaRecorder.mimeType) {
          this.currentMimeType = this.mediaRecorder.mimeType;
        }
        console.log('âš ï¸ ä½¿ç”¨é»˜è®¤ MediaRecorder é…ç½®ï¼Œæ ¼å¼:', this.currentMimeType);
      }

      // ç›‘å¬æ•°æ®
      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data);
        }
      };

      const recordingStartTime = Date.now();
      
      // å½•éŸ³ç»“æŸ
      this.mediaRecorder.onstop = async () => {
        try {
          const recordingDuration = Date.now() - recordingStartTime;
          console.log(`â±ï¸ å½•éŸ³æ—¶é•¿: ${recordingDuration}ms`);
          
          if (recordingDuration < 500) {
            console.warn('âš ï¸ å½•éŸ³æ—¶é•¿è¿‡çŸ­ï¼Œå¯èƒ½å½±å“è¯†åˆ«å‡†ç¡®ç‡');
            this.onErrorCallback?.('å½•éŸ³æ—¶é•¿è¿‡çŸ­ï¼Œè¯·è‡³å°‘å½•éŸ³0.5ç§’');
            stream.getTracks().forEach(track => track.stop());
            return;
          }
          
          // åˆå¹¶éŸ³é¢‘æ•°æ®
          const audioBlob = new Blob(this.audioChunks, { type: this.currentMimeType });
          
          if (audioBlob.size < 1000) {
            console.warn('âš ï¸ éŸ³é¢‘æ•°æ®è¿‡å°ï¼Œå¯èƒ½å½•éŸ³å¤±è´¥');
            this.onErrorCallback?.('å½•éŸ³æ•°æ®å¼‚å¸¸ï¼Œè¯·é‡è¯•');
            stream.getTracks().forEach(track => track.stop());
            return;
          }
          
          // è½¬æ¢ä¸º WAV æ ¼å¼å¹¶å‘é€è¯†åˆ«è¯·æ±‚
          console.log('ğŸ“ å¼€å§‹è½¬æ¢éŸ³é¢‘æ ¼å¼:', this.currentMimeType, '-> wav');
          const wavBlob = await this.convertAudioToWav(audioBlob, stream);
          const text = await this.recognizeAudio(wavBlob);
          this.onResultCallback?.(text);
          
          stream.getTracks().forEach(track => track.stop());
        } catch (error: any) {
          console.error('âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
          this.onErrorCallback?.(error.message || 'è¯†åˆ«å¤±è´¥');
          stream.getTracks().forEach(track => track.stop());
        }
      };

      // å¼€å§‹å½•éŸ³
      this.mediaRecorder.start();
      this.isListening = true;
      console.log('âœ… å½•éŸ³å·²å¼€å§‹');
    } catch (error: any) {
      const browserInfo = getBrowserInfo();
      console.error('âŒ å¯åŠ¨å½•éŸ³å¤±è´¥:', {
        error: error.message || error,
        name: error.name,
        browserInfo: browserInfo,
      });
      
      let errorMessage = 'æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®';
      if (error.name === 'NotAllowedError') {
        errorMessage = 'éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£';
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡';
      } else if (error.name === 'NotSupportedError') {
        errorMessage = 'å½“å‰æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½';
      }
      
      onError?.(errorMessage);
    }
  }

  /**
   * åœæ­¢è¯­éŸ³è¯†åˆ«
   */
  stop() {
    if (this.mediaRecorder && this.isListening) {
      this.mediaRecorder.stop();
      this.isListening = false;
    }
  }

  /**
   * å°†éŸ³é¢‘è½¬æ¢ä¸º WAV æ ¼å¼
   */
  private async convertAudioToWav(audioBlob: Blob, stream: MediaStream): Promise<Blob> {
    return new Promise((resolve, reject) => {
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const fileReader = new FileReader();
      
      fileReader.onload = async () => {
        try {
          const audioBuffer = await audioContext.decodeAudioData(fileReader.result as ArrayBuffer);
          
          const { rate } = XUNFEI_SPEECH_CONFIG.recognition;
          const sampleRate = rate;
          
          let processedBuffer = audioBuffer;
          if (audioBuffer.sampleRate !== sampleRate) {
            console.log(`ğŸ”„ é‡é‡‡æ ·: ${audioBuffer.sampleRate}Hz -> ${sampleRate}Hz`);
            processedBuffer = await this.resampleAudio(audioBuffer, sampleRate);
          }
          
          processedBuffer = this.normalizeAudio(processedBuffer);
          
          const wavBuffer = this.audioBufferToWav(processedBuffer);
          const wavBlob = new Blob([wavBuffer], { type: 'audio/wav' });
          
          console.log('âœ… éŸ³é¢‘æ ¼å¼è½¬æ¢æˆåŠŸ:', {
            åŸå§‹æ ¼å¼: audioBlob.type,
            åŸå§‹å¤§å°: `${(audioBlob.size / 1024).toFixed(2)} KB`,
            è½¬æ¢åå¤§å°: `${(wavBlob.size / 1024).toFixed(2)} KB`,
            é‡‡æ ·ç‡: `${sampleRate}Hz`
          });
          
          resolve(wavBlob);
        } catch (error) {
          console.error('âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥:', error);
          reject(error);
        } finally {
          audioContext.close();
        }
      };
      
      fileReader.onerror = reject;
      fileReader.readAsArrayBuffer(audioBlob);
    });
  }

  /**
   * é‡é‡‡æ ·éŸ³é¢‘
   */
  private async resampleAudio(audioBuffer: AudioBuffer, targetSampleRate: number): Promise<AudioBuffer> {
    const sourceSampleRate = audioBuffer.sampleRate;
    const numberOfChannels = audioBuffer.numberOfChannels;
    const length = Math.round(audioBuffer.length * targetSampleRate / sourceSampleRate);
    
    const offlineContext = new OfflineAudioContext(numberOfChannels, length, targetSampleRate);
    const bufferSource = offlineContext.createBufferSource();
    bufferSource.buffer = audioBuffer;
    bufferSource.connect(offlineContext.destination);
    bufferSource.start(0);
    return await offlineContext.startRendering();
  }

  /**
   * éŸ³é¢‘å½’ä¸€åŒ–
   */
  private normalizeAudio(audioBuffer: AudioBuffer): AudioBuffer {
    const numberOfChannels = audioBuffer.numberOfChannels;
    const length = audioBuffer.length;
    const sampleRate = audioBuffer.sampleRate;
    
    let maxAmplitude = 0;
    for (let channel = 0; channel < numberOfChannels; channel++) {
      const channelData = audioBuffer.getChannelData(channel);
      for (let i = 0; i < length; i++) {
        const abs = Math.abs(channelData[i]);
        if (abs > maxAmplitude) {
          maxAmplitude = abs;
        }
      }
    }
    
    if (maxAmplitude > 0 && maxAmplitude < 0.5) {
      const gain = 0.8 / maxAmplitude;
      const normalizedBuffer = new AudioBuffer({
        numberOfChannels,
        length,
        sampleRate
      });
      
      for (let channel = 0; channel < numberOfChannels; channel++) {
        const inputData = audioBuffer.getChannelData(channel);
        const outputData = normalizedBuffer.getChannelData(channel);
        for (let i = 0; i < length; i++) {
          outputData[i] = inputData[i] * gain;
        }
      }
      
      console.log(`ğŸ”Š éŸ³é¢‘å½’ä¸€åŒ–: å¢ç›Š ${gain.toFixed(2)}x`);
      return normalizedBuffer;
    }
    
    return audioBuffer;
  }

  /**
   * å°† AudioBuffer è½¬æ¢ä¸º WAV æ ¼å¼
   */
  private audioBufferToWav(buffer: AudioBuffer): ArrayBuffer {
    const numChannels = buffer.numberOfChannels;
    const sampleRate = buffer.sampleRate;
    const format = 1;
    const bitDepth = 16;
    
    const bytesPerSample = bitDepth / 8;
    const blockAlign = numChannels * bytesPerSample;
    
    const length = buffer.length;
    const arrayBuffer = new ArrayBuffer(44 + length * numChannels * bytesPerSample);
    const view = new DataView(arrayBuffer);
    
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + length * numChannels * bytesPerSample, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, format, true);
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * blockAlign, true);
    view.setUint16(32, blockAlign, true);
    view.setUint16(34, bitDepth, true);
    writeString(36, 'data');
    view.setUint32(40, length * numChannels * bytesPerSample, true);
    
    let offset = 44;
    for (let i = 0; i < length; i++) {
      for (let channel = 0; channel < numChannels; channel++) {
        const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]));
        view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
        offset += 2;
      }
    }
    
    return arrayBuffer;
  }

  /**
   * é€šè¿‡æœåŠ¡ç«¯ä»£ç†è°ƒç”¨è®¯é£è¯­éŸ³è¯†åˆ«API
   */
  private async recognizeAudio(audioBlob: Blob): Promise<string> {
    const base64Audio = await this.blobToBase64(audioBlob);
    const { format, rate } = XUNFEI_SPEECH_CONFIG.recognition;
    
    const base64Data = base64Audio.replace(/^data:[^,]*,/, '');

    console.log('ğŸ“¤ é€šè¿‡æœåŠ¡ç«¯ä»£ç†å‘é€è¯­éŸ³è¯†åˆ«è¯·æ±‚ï¼ˆè®¯é£ï¼‰:', {
      è¯·æ±‚URL: '/api/asr/xunfei',
      å½“å‰åŸŸå: window.location.origin
    });

    const controller = new AbortController();
    const timeoutId = setTimeout(() => {
      controller.abort();
    }, 30000);

    let response;
    try {
      response = await fetch('/api/asr/xunfei', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          format,
          rate,
          base64: base64Audio,
        }),
        signal: controller.signal,
      });
      clearTimeout(timeoutId);
    } catch (fetchError: any) {
      clearTimeout(timeoutId);
      if (fetchError.name === 'AbortError') {
        throw new Error('è¯­éŸ³è¯†åˆ«è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•');
      }
      throw fetchError;
    }

    if (!response.ok) {
      const errorText = await response.text().catch(() => 'æ— æ³•è¯»å–é”™è¯¯ä¿¡æ¯');
      console.error('âŒ æœåŠ¡ç«¯å“åº”é”™è¯¯:', {
        status: response.status,
        statusText: response.statusText,
        body: errorText.substring(0, 200)
      });
      throw new Error(`æœåŠ¡ç«¯é”™è¯¯: HTTP ${response.status} ${response.statusText}`);
    }

    const responseText = await response.text();
    
    if (!responseText || responseText.trim().length === 0) {
      console.error('âŒ æœåŠ¡ç«¯è¿”å›ç©ºå“åº”');
      throw new Error('æœåŠ¡ç«¯è¿”å›ç©ºå“åº”ï¼Œè¯·æ£€æŸ¥æœåŠ¡ç«¯æ—¥å¿—');
    }

    let result;
    try {
      result = JSON.parse(responseText);
    } catch (parseError: any) {
      console.error('âŒ JSONè§£æå¤±è´¥:', {
        error: parseError.message,
        responseText: responseText.substring(0, 200),
      });
      throw new Error(`å“åº”æ ¼å¼é”™è¯¯: ${parseError.message}`);
    }
    
    console.log('ğŸ“¥ è®¯é£è¯­éŸ³è¯†åˆ«å“åº”:', {
      text: result.text
    });
    
    if (result?.text) {
      console.log('âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸï¼ˆè®¯é£ï¼‰:', result.text);
      return result.text;
    }
    
    const errorMsg = result?.error_description || result?.error || 'è¯†åˆ«å¤±è´¥';
    console.error('âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼ˆè®¯é£ï¼‰:', result);
    throw new Error(errorMsg);
  }

  /**
   * å°† Blob è½¬æ¢ä¸º Base64
   */
  private blobToBase64(blob: Blob): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => {
        if (typeof reader.result === 'string') {
          resolve(reader.result);
        } else {
          reject(new Error('è½¬æ¢å¤±è´¥'));
        }
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }

  /**
   * è·å–å½“å‰æ˜¯å¦æ­£åœ¨ç›‘å¬
   */
  getIsListening(): boolean {
    return this.isListening;
  }
}

/**
 * è®¯é£è¯­éŸ³åˆæˆç±»
 */
export class XunfeiSpeechSynthesizer {
  private audio: HTMLAudioElement | null = null;
  private isSpeaking: boolean = false;
  private currentAudioUrl: string | null = null;

  /**
   * æ’­æŠ¥æ–‡æœ¬ï¼ˆæ”¯æŒè§’è‰²éŸ³è‰²ï¼‰
   */
  async speak(
    text: string,
    options?: {
      characterId?: string; // è§’è‰²IDï¼Œç”¨äºé€‰æ‹©éŸ³è‰²
      onEnd?: () => void;
      onError?: (error: any) => void;
    }
  ) {
    // åœæ­¢å½“å‰æ’­æŠ¥
    this.stop();

    try {
      const browserInfo = getBrowserInfo();
      console.log('ğŸ”Š å¼€å§‹è¯·æ±‚è¯­éŸ³åˆæˆï¼ˆè®¯é£ï¼‰:', { 
        textLength: text.length,
        characterId: options?.characterId,
        browserInfo: browserInfo
      });

      // æ ¹æ®è§’è‰²IDè·å–éŸ³è‰²é…ç½®
      const characterId = options?.characterId || 'escort';
      const voiceConfig = XUNFEI_SPEECH_CONFIG.characterVoices[characterId as keyof typeof XUNFEI_SPEECH_CONFIG.characterVoices] 
        || XUNFEI_SPEECH_CONFIG.characterVoices.escort;

      console.log('ğŸµ ä½¿ç”¨éŸ³è‰²é…ç½®:', {
        è§’è‰²ID: characterId,
        éŸ³è‰²: voiceConfig.vcn,
        è¯­é€Ÿ: voiceConfig.speed,
        éŸ³è°ƒ: voiceConfig.pitch,
      });

      // é€šè¿‡æœåŠ¡ç«¯ä»£ç†è°ƒç”¨è®¯é£API
      const audioBlob = await this.speakViaProxy(text, voiceConfig);
      console.log('âœ… è¯­éŸ³åˆæˆæˆåŠŸï¼ˆè®¯é£ï¼‰ï¼ŒéŸ³é¢‘å¤§å°:', `${(audioBlob.size / 1024).toFixed(2)} KB`);

      // æ¸…ç†ä¹‹å‰çš„ URL å¯¹è±¡
      if (this.currentAudioUrl) {
        URL.revokeObjectURL(this.currentAudioUrl);
      }
      this.currentAudioUrl = URL.createObjectURL(audioBlob);

      // åˆ›å»ºéŸ³é¢‘å…ƒç´ 
      this.audio = new Audio(this.currentAudioUrl);
      this.audio.preload = 'auto';
      
      // ç­‰å¾…éŸ³é¢‘åŠ è½½å®Œæˆ
      await new Promise<void>((resolve, reject) => {
        if (!this.audio) {
          reject(new Error('éŸ³é¢‘å…ƒç´ æœªåˆ›å»º'));
          return;
        }

        const timeout = setTimeout(() => {
          reject(new Error('éŸ³é¢‘åŠ è½½è¶…æ—¶'));
        }, 10000);

        this.audio!.onloadeddata = () => {
          clearTimeout(timeout);
          console.log('âœ… è¯­éŸ³åŠ è½½å®Œæˆ');
          resolve();
        };

        this.audio!.onerror = (event) => {
          clearTimeout(timeout);
          const error = new Error('éŸ³é¢‘åŠ è½½å¤±è´¥');
          console.error('âŒ è¯­éŸ³åŠ è½½å¤±è´¥:', event);
          reject(error);
        };

        if (this.audio.readyState >= 2) {
          clearTimeout(timeout);
          resolve();
        }
      });

      // æ¸…ç† URL å¯¹è±¡ï¼ˆæ’­æ”¾å®Œæˆåï¼‰
      this.audio.onended = () => {
        this.isSpeaking = false;
        console.log('âœ… è¯­éŸ³æ’­æ”¾å®Œæˆ');
        if (this.currentAudioUrl) {
          URL.revokeObjectURL(this.currentAudioUrl);
          this.currentAudioUrl = null;
        }
        options?.onEnd?.();
      };

      this.audio.onplay = () => {
        this.isSpeaking = true;
        console.log('â–¶ï¸ è¯­éŸ³å¼€å§‹æ’­æ”¾');
      };

      this.audio.onerror = (event) => {
        this.isSpeaking = false;
        const error = this.audio?.error;
        const errorMsg = error 
          ? `æ’­æ”¾é”™è¯¯: ${error.code} - ${error.message}`
          : 'éŸ³é¢‘æ’­æ”¾å¤±è´¥';
        console.error('âŒ è¯­éŸ³æ’­æ”¾å¤±è´¥:', {
          event,
          error: errorMsg,
        });
        if (this.currentAudioUrl) {
          URL.revokeObjectURL(this.currentAudioUrl);
          this.currentAudioUrl = null;
        }
        options?.onError?.(new Error(errorMsg));
      };

      // å°è¯•æ’­æ”¾éŸ³é¢‘
      try {
        const playPromise = this.audio.play();
        if (playPromise !== undefined) {
          await playPromise;
        }
        console.log('âœ… è¯­éŸ³æ’­æ”¾å·²å¯åŠ¨');
      } catch (playError: any) {
        console.error('âŒ è¯­éŸ³æ’­æ”¾å¯åŠ¨å¤±è´¥:', playError);
        if (this.currentAudioUrl) {
          URL.revokeObjectURL(this.currentAudioUrl);
          this.currentAudioUrl = null;
        }
        const errorMsg = playError.message || 'æ— æ³•æ’­æ”¾éŸ³é¢‘ï¼Œè¯·æ£€æŸ¥æ˜¯å¦åœ¨ç”¨æˆ·äº¤äº’ä¸­è§¦å‘';
        throw new Error(errorMsg);
      }
    } catch (error: any) {
      console.error('âŒ è®¯é£è¯­éŸ³åˆæˆå¤±è´¥:', error);
      this.isSpeaking = false;
      const errorMsg = error?.message || 'è¯­éŸ³åˆæˆæœåŠ¡å¤±è´¥';
      options?.onError?.(error instanceof Error ? error : new Error(errorMsg));
    }
  }

  /**
   * é€šè¿‡æœåŠ¡ç«¯ä»£ç†è°ƒç”¨è®¯é£è¯­éŸ³åˆæˆAPI
   */
  private async speakViaProxy(
    text: string,
    voiceConfig: typeof XUNFEI_SPEECH_CONFIG.characterVoices.escort
  ): Promise<Blob> {
    const requestUrl = '/api/tts/xunfei';
    console.log('ğŸ“¤ é€šè¿‡æœåŠ¡ç«¯ä»£ç†å‘é€è¯­éŸ³åˆæˆè¯·æ±‚ï¼ˆè®¯é£ï¼‰:', {
      è¯·æ±‚URL: requestUrl,
      å½“å‰åŸŸå: window.location.origin
    });

    const response = await fetch(requestUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        text,
        vcn: voiceConfig.vcn,
        speed: voiceConfig.speed,
        pitch: voiceConfig.pitch,
        volume: voiceConfig.volume,
        aue: voiceConfig.aue,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(errorData.error_description || `è¯·æ±‚å¤±è´¥: ${response.status}`);
    }

    // è·å–éŸ³é¢‘æ•°æ®
    return await response.blob();
  }

  /**
   * åœæ­¢æ’­æŠ¥
   */
  stop() {
    if (this.audio) {
      this.audio.pause();
      this.audio.currentTime = 0;
      this.audio = null;
      this.isSpeaking = false;
    }
    if (this.currentAudioUrl) {
      URL.revokeObjectURL(this.currentAudioUrl);
      this.currentAudioUrl = null;
    }
  }

  /**
   * æš‚åœæ’­æŠ¥
   */
  pause() {
    if (this.audio && this.isSpeaking) {
      this.audio.pause();
    }
  }

  /**
   * æ¢å¤æ’­æŠ¥
   */
  resume() {
    if (this.audio && !this.isSpeaking) {
      this.audio.play();
    }
  }

  /**
   * è·å–å½“å‰æ˜¯å¦æ­£åœ¨æ’­æŠ¥
   */
  getIsSpeaking(): boolean {
    return this.isSpeaking;
  }
}

